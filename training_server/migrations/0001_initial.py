# -*- coding: utf-8 -*-
# Generated by Django 1.11 on 2018-12-29 15:36
from __future__ import unicode_literals

import django.contrib.postgres.fields
from django.db import migrations, models
import django.db.models.deletion


class Migration(migrations.Migration):

    initial = True

    dependencies = [
    ]

    operations = [
        migrations.CreateModel(
            name='AlgorithmConfig',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('framework', models.CharField(choices=[('auto_sklearn', 'Auto-sklearn'), ('tpot', 'TPOT')], max_length=24)),
                ('model_path', models.CharField(blank=True, help_text='Path to the model', max_length=256, null=True)),
                ('status', models.CharField(blank=True, choices=[('waiting', 'Waiting for thread'), ('in_progress', 'In progress'), ('success', 'Success'), ('fail', 'Fail')], help_text='Status of the training', max_length=32, null=True)),
                ('date_trained', models.DateTimeField(auto_now=True)),
                ('training_triggered', models.BooleanField(default=False, help_text='Helper Flag for defining which config should be updateable (which one has not yet been trained)')),
                ('additional_remarks', models.CharField(blank=True, help_text='Additional Information about the training. E.g. Information about failed trainings are logged here in case a training fails!', max_length=2048, null=True)),
            ],
        ),
        migrations.CreateModel(
            name='AutoSklearnConfig',
            fields=[
                ('algorithmconfig_ptr', models.OneToOneField(auto_created=True, on_delete=django.db.models.deletion.CASCADE, parent_link=True, primary_key=True, serialize=False, to='training_server.AlgorithmConfig')),
                ('run_time', models.IntegerField(blank=True, default=3600, help_text='Default: 3600. Time limit in seconds for the search of appropriate models. By increasing this value, the system has a higher chance of finding better models.!', null=True)),
                ('per_instance_runtime', models.IntegerField(blank=True, default=360, help_text='Default: 360. Time limit for a single call to the machine learning model. Model fitting will be terminated if the machine learning algorithm runs over the time limit. Set this value high enough so that typical machine learning algorithms can be fit on the training data.', null=True)),
                ('initial_configurations_via_metalearning', models.IntegerField(blank=True, default=25, help_text='Default: 25. Initialize the hyperparameter optimization algorithm with this many configurations which worked well on previously seen datasets. Disable if the hyperparameter optimization algorithm should start from scratch.', null=True)),
                ('memory_limit', models.IntegerField(blank=True, default=3072, help_text='Default: 3072, Memory Limit for the Training.', null=True)),
                ('ensemble_size', models.IntegerField(blank=True, default=50, help_text='Default: 50, Number of models added to the ensemble built by Ensemble selection from libraries of models. Models are drawn with replacement.', null=True)),
                ('ensemble_nbest', models.IntegerField(blank=True, default=50, help_text='Default: 1, Only consider the ensemble_nbest models when building an ensemble. Implements Model Library Pruning from Getting the most out of ensemble selection.', null=True)),
                ('seed', models.IntegerField(blank=True, default=1, help_text='Default: 1, Only consider the ensemble_nbest models when building an ensemble. Implements Model Library Pruning from Getting the most out of ensemble selection.', null=True)),
                ('include_estimators', django.contrib.postgres.fields.ArrayField(base_field=models.CharField(blank=True, max_length=64, null=True), blank=True, choices=[(('random_forest',), 'random_forest'), ('adaboost', 'adaboost'), ('bernoulli_nb', 'bernoulli_nb'), ('decission_tree', 'decission_tree'), ('extra_trees', 'extra_trees'), ('gaussian_nb', 'guassian_nb'), ('gaussian_process', 'gaussian_process'), ('gradient_boosting', 'gradient_boosting'), ('k_nearest_neighbors', 'k_nearest_neighbors'), ('ida', 'ida'), ('liblinear_svr', 'liblinear_svr'), ('libsvm_svr', 'libsvm_svr'), ('liblinear_svc', 'liblineaer_svc'), ('libsvm_svc', 'libsvm_svc'), ('multinomial_nb', 'multinomial_nb'), ('passive_aggressive', 'passive_aggressive'), (('random_forest',), 'random_forest'), ('ridge_regression', 'ridge_regression'), ('qda', 'qda'), ('sgd', 'sgd'), ('xgradient_boosting', 'xgradient_boosting')], default=None, help_text='Default: None, If None, all possible estimators are used. Otherwise specifies set of estimators to use.', null=True, size=50)),
                ('exclude_estimators', django.contrib.postgres.fields.ArrayField(base_field=models.CharField(blank=True, max_length=64, null=True), blank=True, choices=[(('random_forest',), 'random_forest'), ('adaboost', 'adaboost'), ('bernoulli_nb', 'bernoulli_nb'), ('decission_tree', 'decission_tree'), ('extra_trees', 'extra_trees'), ('gaussian_nb', 'guassian_nb'), ('gaussian_process', 'gaussian_process'), ('gradient_boosting', 'gradient_boosting'), ('k_nearest_neighbors', 'k_nearest_neighbors'), ('ida', 'ida'), ('liblinear_svr', 'liblinear_svr'), ('libsvm_svr', 'libsvm_svr'), ('liblinear_svc', 'liblineaer_svc'), ('libsvm_svc', 'libsvm_svc'), ('multinomial_nb', 'multinomial_nb'), ('passive_aggressive', 'passive_aggressive'), (('random_forest',), 'random_forest'), ('ridge_regression', 'ridge_regression'), ('qda', 'qda'), ('sgd', 'sgd'), ('xgradient_boosting', 'xgradient_boosting')], default=None, help_text='Default: None, If None, all possible estimators are used. Otherwise specifies set of estimators not to use. Incompatible with include_estimators.', null=True, size=50)),
                ('include_preprocessors', django.contrib.postgres.fields.ArrayField(base_field=models.CharField(blank=True, max_length=64, null=True), blank=True, choices=[('balancing', 'balancing'), ('imputation', 'imputation'), ('one_hot_encoding', 'one_hot_encoding'), ('rescalling', 'rescalling'), ('variance', 'variance'), ('densifier', 'densifier'), ('extra_trees_preproc_for_classification', 'extra_trees_preproc_for_classification'), ('extra_trees_preproc_for_regression', 'extra_trees_preproc_for_regression'), ('fast_ica', 'fast_ica'), ('feature_agglomeration', 'feature_agglomeration'), ('kernel_pca', 'kernel_pca'), ('kitchen_sinks', 'kitchen_sinks'), ('liblinear_svc_preprocessors', 'liblinear_svc_preprocessors'), ('no_preprocessing', 'no_preprocessing'), ('nystroem_sampler', 'nystroem_sampler'), ('pca', 'pca'), ('polynomial', 'polynomial'), ('random_trees_embedding', 'random_trees_embedding'), ('select_percentile', 'select_percentile'), ('select_percentile_classification', 'select_percentile_classification'), ('select_percentile_regression', 'select_percentile_regression'), ('select_rates', 'select_rates'), ('truncatedsvd', 'truncatedsvd')], default=None, help_text='Default: None, If None all possible preprocessors are used. Otherwise specifies set of preprocessors to use.', null=True, size=50)),
                ('exclude_preprocessors', django.contrib.postgres.fields.ArrayField(base_field=models.CharField(blank=True, max_length=64, null=True), blank=True, choices=[('balancing', 'balancing'), ('imputation', 'imputation'), ('one_hot_encoding', 'one_hot_encoding'), ('rescalling', 'rescalling'), ('variance', 'variance'), ('densifier', 'densifier'), ('extra_trees_preproc_for_classification', 'extra_trees_preproc_for_classification'), ('extra_trees_preproc_for_regression', 'extra_trees_preproc_for_regression'), ('fast_ica', 'fast_ica'), ('feature_agglomeration', 'feature_agglomeration'), ('kernel_pca', 'kernel_pca'), ('kitchen_sinks', 'kitchen_sinks'), ('liblinear_svc_preprocessors', 'liblinear_svc_preprocessors'), ('no_preprocessing', 'no_preprocessing'), ('nystroem_sampler', 'nystroem_sampler'), ('pca', 'pca'), ('polynomial', 'polynomial'), ('random_trees_embedding', 'random_trees_embedding'), ('select_percentile', 'select_percentile'), ('select_percentile_classification', 'select_percentile_classification'), ('select_percentile_regression', 'select_percentile_regression'), ('select_rates', 'select_rates'), ('truncatedsvd', 'truncatedsvd')], default=None, help_text='Default: None, If None all possible preprocessors are used. Otherwise specifies set of preprocessors not to use. Incompatible with include_preprocessors.', null=True, size=50)),
                ('resampling_strategy', models.CharField(blank=True, choices=[('holdout', 'holdout'), ('holdout_iterative_fit', 'holdout_iterative_fit'), ('cv', 'cv'), ('partial_cv', 'partial_cv')], default='holdout', help_text='Default: Holdout, how to to handle overfitting, might need ‘resampling_strategy_arguments’; Available arguments: ‘holdout’: {‘train_size’: float};‘holdout-iterative-fit’: {‘train_size’: float} ‘cv’: {‘folds’: int}‘partial-cv’: {‘folds’: int, ‘shuffle’: bool}', max_length=128, null=True)),
                ('tmp_folder', models.CharField(blank=True, default=None, help_text='Default: None, folder to store configuration output and log files, if None automatically use /tmp/autosklearn_tmp_$pid_$random_number', max_length=256, null=True)),
                ('output_folder', models.CharField(blank=True, default=None, help_text='Default: None, folder to store predictions for optional test set, if None automatically use , if None automatically use /tmp/autosklearn_output_$pid_$random_number', max_length=256, null=True)),
                ('delete_tmp_folder_after_terminate', models.NullBooleanField(default=True, help_text='Default: True, remove tmp_folder, when finished. If tmp_folder is None tmp_dir will always be deleted')),
                ('delete_output_folder_after_terminate', models.NullBooleanField(default=True, help_text='Default: True, remove output_folder, when finished. If output_folder is None output_dir will always be deleted')),
                ('shared_mode', models.NullBooleanField(default=False, help_text='Default: False, Run smac in shared-model-node. This only works if arguments tmp_folder and output_folder are given and both delete_tmp_folder_after_terminate and delete_output_folder_after_terminate are set to False.')),
                ('smac_scenario_args', models.CharField(blank=True, default=None, help_text='Default: None, Additional arguments inserted into the scenario of SMAC. See the SMAC documentation for a list of available arguments.', max_length=1024, null=True)),
                ('logging_config', models.CharField(blank=True, help_text='dictionary object specifying the logger configuration. If None, the default logging.yaml file is used, which can be found in the directory util/logging.yaml relative to the installation.', max_length=1024, null=True)),
            ],
            bases=('training_server.algorithmconfig',),
        ),
        migrations.CreateModel(
            name='TpotConfig',
            fields=[
                ('algorithmconfig_ptr', models.OneToOneField(auto_created=True, on_delete=django.db.models.deletion.CASCADE, parent_link=True, primary_key=True, serialize=False, to='training_server.AlgorithmConfig')),
                ('generations', models.IntegerField(blank=True, default=100, help_text='Number of iterations to the run pipeline optimization process. Must be a positive number. Generally, TPOT will work better when you give it more generations (and therefore time) to optimize the pipeline. TPOT will evaluate population_size + generations × offspring_size pipelines in total.', null=True)),
                ('population_size', models.IntegerField(blank=True, default=100, help_text='Number of individuals to retain in the genetic programming population every generation. Must be a positive number. Generally, TPOT will work better when you give it more individuals with which to optimize the pipeline.', null=True)),
                ('offspring_size', models.IntegerField(blank=True, default=100, help_text='Number of offspring to produce in each genetic programming generation. Must be a positive number.', null=True)),
                ('mutation_rate', models.FloatField(blank=True, default=0.9, help_text='Mutation rate for the genetic programming algorithm in the range [0.0, 1.0]. This parameter tells the GP algorithm how many pipelines to apply random changes to every generation. mutation_rate + crossover_rate cannot exceed 1.0. We recommend using the default parameter unless you understand how the mutation rate affects GP algorithms.', null=True)),
                ('crossover_rate', models.FloatField(blank=True, default=0.1, help_text='Crossover rate for the genetic programming algorithm in the range [0.0, 1.0]. This parameter tells the genetic programming algorithm how many pipelines to "breed" every generation. mutation_rate + crossover_rate cannot exceed 1.0. We recommend using the default parameter unless you understand how the crossover rate affects GP algorithms.', null=True)),
                ('scoring', models.CharField(blank=True, choices=[('accuracy', 'accuracy'), ('adjusted_rand_score', 'adjusted_rand_score'), ('average_precision', 'average_precision'), ('balanced_accuracy', 'balanced_accuracy'), ('f1', 'f1'), ('f1_macro', 'f1_macro'), ('f1_micro', 'f1_micro'), ('f1_samples', 'f1_samples'), ('f1_weighted', 'f1_weighted'), ('neg_log_loss', 'neg_log_loss'), ('precision', 'precision'), ('precision_macro', 'precision_macro'), ('precision_micro', 'precision_micro'), ('precision_samples', 'precision_samples'), ('precision_weighted', 'precision_weighted'), ('recall', 'recall'), ('recall_macro', 'recall_macro'), ('recall_micro', 'recall_micro'), ('recall_samples', 'recall_samples'), ('recall_weighted', 'recall_weighted'), ('roc_auc', 'roc_auc')], default='accuracy', help_text='Function used to evaluate the quality of a given pipeline for the classification problem.', max_length=50, null=True)),
                ('cv', models.IntegerField(blank=True, default=5, help_text='Specify the number of folds in a StratifiedKFold.', null=True)),
                ('subsample', models.FloatField(blank=True, default=1.0, help_text='Fraction of training samples that are used during the TPOT optimization process. Must be in the range (0.0, 1.0].  Setting subsample=0.5 tells TPOT to use a random subsample of half of the training data. This subsample will remain the same during the entire pipeline optimization process.', null=True)),
                ('n_jobs', models.IntegerField(blank=True, default=1, help_text='Number of processes to use in parallel for evaluating pipelines during the TPOT optimization process. Setting n_jobs=-1 will use as many cores as available on the computer. Beware that using multiple processes on the same machine may cause memory issues for large datasets', null=True)),
                ('max_time_mins', models.IntegerField(blank=True, default=None, help_text='How many minutes TPOT has to optimize the pipeline. If not None, this setting will override the generations parameter and allow TPOT to run until max_time_mins minutes elapse.', null=True)),
                ('max_eval_time_mins', models.IntegerField(blank=True, default=None, help_text='How many minutes TPOT has to evaluate a single pipeline. Setting this parameter to higher values will allow TPOT to evaluate more complex pipelines, but will also allow TPOT to run longer. Use this parameter to help prevent TPOT from wasting time on evaluating time-consuming pipelines.', null=True)),
                ('random_state', models.IntegerField(blank=True, default=None, help_text='The seed of the pseudo random number generator used in TPOT. Use this parameter to make sure that TPOT will give you the same results each time you run it against the same data set with that seed.', null=True)),
                ('config_dict', models.CharField(blank=True, choices=[('TPOT light', 'TPOT light'), ('TPOT MDR', 'TPOT MDR'), ('TPOT sparse', 'TPOT sparse')], default=None, help_text="A configuration dictionary for customizing the operators and parameters that TPOT searches in the optimization process.\nPossible inputs are:\n string 'TPOT light', TPOT will use a built-in configuration with only fast models and preprocessors, or \nstring 'TPOT MDR', TPOT will use a built-in configuration specialized for genomic studies, or \nstring 'TPOT sparse': TPOT will use a configuration dictionary with a one-hot encoder and the operators normally included in TPOT that also support sparse matrices, or \nNone, TPOT will use the default TPOTClassifier configuration.", max_length=50, null=True)),
                ('warm_start', models.NullBooleanField(default=False, help_text='Flag indicating whether the TPOT instance will reuse the population from previous calls to fit(). Setting warm_start=True can be useful for running TPOT for a short time on a dataset, checking the results, then resuming the TPOT run from where it left off.')),
                ('memory', models.CharField(blank=True, choices=[('auto', 'auto'), (None, 'none')], default=None, help_text="String 'auto': TPOT uses memory caching with a temporary directory and cleans it up upon shutdown, or None, TPOT does not use memory caching.", max_length=50, null=True)),
                ('use_dask', models.NullBooleanField(default=False, help_text="Whether to use Dask-ML's pipeline optimiziations. This avoid re-fitting the same estimator on the same split of data multiple times. It will also provide more detailed diagnostics when using Dask's distributed scheduler.")),
                ('early_stop', models.IntegerField(blank=True, default=None, help_text='How many generations TPOT checks whether there is no improvement in optimization process. Ends the optimization process if there is no improvement in the given number of generations.', null=True)),
                ('verbosity', models.IntegerField(blank=True, choices=[(0, 0), (1, 1), (2, 2), (3, 3)], default=0, help_text="How much information TPOT communicates while it's running. \nPossible inputs are:\n0, TPOT will print nothing,\n1, TPOT will print minimal information,\n2, TPOT will print more information and provide a progress bar, or\n3, TPOT will print everything and provide a progress bar.", null=True)),
                ('disable_update_check', models.NullBooleanField(default=False, help_text='Flag indicating whether the TPOT version checker should be disabled. The update checker will tell you when a new version of TPOT has been released.')),
            ],
            bases=('training_server.algorithmconfig',),
        ),
    ]
